# 千万级数据表查询优化实战

## 背景

最近在修复一个业务两端标签数据一致性问题的时候想起标签导出功能的速度一直非常缓慢，于是顺便就把这个问题一道解决了，该功能是根据标签名称、打标人以及打标时间筛选出打标数据，然后导出。主表的数据有4000w多万，导出功能有一个连表查询，连接表数据量600w，查询条件的索引也都有建，但是当导出的数据量超过2-3w的时候就会超时无法导出

## 问题分析

### 主表结构

|主键ID|客户ID|标签ID|打标时间|添加人|
|---|---|---|---|---

### 副表结构
|客户ID（唯一）|客户信息|客户添加时间|
|---|---|---|

### 原sql大概类似

```sql
select `主表`.'部分信息',`副表`.'部分信息' from 主表 
left join 副表 on `主表`.客户ID left join `副表`.客户ID 
where `主表`.标签ID = '111' and `副表`.客户添加时间 between '2018-01-01 00:00:00' and '2022-01-01 00:00:00' and  `主表`.添加人='1234'
order by `副表`.客户添加时间 desc
```

执行计划

|table|Extra|
|---|---|
|t1|Using where; Using temporary; Using filesort|
|t2|Using where|

## 从业务角度优化

从业务角度来说之前的查询并不符合需求，筛选条件和排序条件是打标时间，而不是客户添加时间，优化完的结果

```sql
select `主表`.'部分信息',`副表`.'部分信息' from 主表 
left join 副表 on `主表`.客户ID left join `副表`.客户ID 
where `主表`.标签ID = '111' and `主表`.打标时间 between '2018-01-01 00:00:00' and '2022-01-01 00:00:00' and  `主表`.添加人=''
order by `主表`.打标时间 desc
```

执行计划

|table|Extra|
|---|---|
|t1|Using index condition; Using where; Using filesort|
|t2|Using index|

这一步很关键，大大简化了sql执行复杂度，条件筛选都在主表中执行，由**根据主表的条件筛选，然后关联副表，再根据副表条件筛选和排序** 变成了 **主表筛选排序完成然后根据唯一键关联副表**，从执行计划可以看出减少了临时表的创建

## 技术优化

经过上一步优化之后，优化起来相对就简单很多了,副表是根据唯一索引键关联的，所以这里我们只讨论主表的索引

### 索引优化

首先创建满足所有查询条件的索引，业务标签ID是必选的，然后根据最左前缀原则，查询频繁度以及字段选择性创建索引及索引顺序：

- 索引1 = 标签ID,打标时间,添加人
- 索引2 = 添加人,标签ID

执行计划
|table|Extra|
|---|---|
|t1|Using index condition|
|t2|Using index|

### 分页优化

由于我们这个功能分为前端展示和导出，前端需要显示查询总数及分页，为了避免大数据量的导出对数据库性能和网络带宽造成太大压力，导出也是使用了分页查询每次查询1000条，并且分页方式也是和查询一样

#### 前端展示分页查询的缺陷

1. 需要统计查询的总数count，大数量的统计总数是非常耗时的操作，即使有索引
2. 使用偏移量（页码*分页大小）+分页大小来分页，深分页数据库需要做大量的io操作，性能非常差

#### 导出查询优化

1. 首先导出是没有计算页码这些需求的，因此优化的目的之一是把count去掉
2. 另外就是避免使用偏移量来分页，我的方案是通过使用主表的主键ID（非连续递增）来代替偏移量

优化结果：

```sql
select `主表`.'部分信息',`副表`.'部分信息' from 主表 
left join 副表 on `主表`.客户ID left join `副表`.客户ID 
where `主表`.标签ID = '111' and `副表`.客户添加时间 between '2018-01-01 00:00:00' and '2022-01-01 00:00:00' and  `主表`.添加人='1234'
and `主表`.主键ID > '主键ID'
order by `主表`.主键ID limit '分页大小'
```

## 优化结果对比

|数据量|操作|优化前|优化后|
|---|---|---|---|
|15w数据|查询|无法查询（超过网关60s的限制）|6s（主要还是count太耗时间）|
|15w数据|导出|无法导出（超过网关60s的限制）|15s|

## 总结

大数据量表的查询优化需要根据业务特点去针对性的进行优化，善于利用索引以及一些技巧去优化，另外count的问题针对大数据量的表属实没有太好的办法，还得靠分库分表去解决
